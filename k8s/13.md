## 2.1

```bash
kubectl get po,sts,svc,pvc
NAME                                        READY   STATUS    RESTARTS      AGE
pod/app-python-585cf68698-58h2t             2/2     Running   0             15s
pod/vault-0                                 1/1     Running   2 (12d ago)   16d
pod/vault-agent-injector-5cd8b87c6c-mbjcf   1/1     Running   2 (12d ago)   16d

NAME                     READY   AGE
statefulset.apps/vault   1/1     16d

NAME                               TYPE           CLUSTER-IP       EXTERNAL-IP   PORT(S)             AGE
service/app-elixir                 LoadBalancer   10.105.31.63     <pending>     4000:31821/TCP      23d
service/app-python                 LoadBalancer   10.97.23.120     <pending>     80:32075/TCP        16d
service/kubernetes                 ClusterIP      10.96.0.1        <none>        443/TCP             30d
service/vault                      ClusterIP      10.109.162.236   <none>        8200/TCP,8201/TCP   16d
service/vault-agent-injector-svc   ClusterIP      10.109.78.200    <none>        443/TCP             16d
service/vault-internal             ClusterIP      None             <none>        8200/TCP,8201/TCP   16d
```

```bash
kubectl exec pod/app-python-0 -- wc -l counter.txt
Defaulted container "app-python" out of: app-python, vault-agent, vault-agent-init (init)
22 counter.txt
```

```bash
kubectl exec pod/app-python-1 -- wc -l counter.txt
Defaulted container "app-python" out of: app-python, vault-agent, vault-agent-init (init)
28 counter.txt
```

```bash
kubectl exec pod/app-python-2 -- wc -l counter.txt
Defaulted container "app-python" out of: app-python, vault-agent, vault-agent-init (init)
32 counter.txt
```

## 2.2

Pods of the same type in this context do not rely on each other. If there were a division of responsibilities—for instance, if one pod was designated for reading data and another for writing—then maintaining a specific sequence would be necessary.

Launching in parallel is implemented using `podManagementPolicy`.

# Bonus.1

Main steps applied to Elixir app.

Update strategies in Kubernetes are the methods used to replace old pods with new ones during a deployment. The primary update strategies are:

- RollingUpdate: This is the default strategy where the Deployment updates pods in a rolling fashion. It gradually replaces the older versions of pods with newer ones, ensuring that a certain number of pods are always running. This strategy minimizes downtime and is suitable for production environments. The key parameters for a RollingUpdate are maxUnavailable and maxSurge which control the number of pods that can be unavailable during the update process and the number of new pods that can be created above the desired number of pods, respectively.

- Recreate: This strategy stops all the old pods before starting new ones. It results in a period of downtime since all pods are killed before any new pod is created. This strategy can be suitable for stateless applications where a brief downtime is acceptable or when a clean start is required for the new version to function properly.

- Blue/Green Deployment: Though not natively supported by Kubernetes as a distinct strategy, it is implemented using service and label selectors. It involves running two versions of an application (blue and green) simultaneously. Once the new version (green) is tested and ready to go live, the traffic is switched from the old version (blue) to the new one. This approach allows for quick rollbacks and minimal downtime but requires double the resources during the switch-over period.

- Canary Releases: Like blue/green deployments, canary releases are not a built-in strategy in Kubernetes but can be implemented using advanced deployment techniques. This strategy involves gradually shifting production traffic from the old version of the application to the new version. A small subset of users is exposed to the new version initially (the "canary"), and if everything goes well, the rollout continues until all users are on the new version.

- A/B Testing: This strategy is similar to Canary Releases but focuses on testing new features with specific user segments or parameters. It's often used for experimentation rather than just updates, allowing developers to gather feedback on new features from live traffic before full deployment.
